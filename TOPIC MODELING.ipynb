{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HDJXNA</td>\n",
       "      <td>1</td>\n",
       "      <td>What I recieved is not what is pictured here O...</td>\n",
       "      <td>12 26, 2012</td>\n",
       "      <td>A29YXBFTD7QUP3</td>\n",
       "      <td>HHA</td>\n",
       "      <td>Buyer be ware</td>\n",
       "      <td>1.356480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B006KKS7XQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent unit and a pretty simple install usi...</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A3IMTXFYD7CGDN</td>\n",
       "      <td>Peter W. George \"soyflakeman\"</td>\n",
       "      <td>high quality without high price</td>\n",
       "      <td>1.379635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002NP8XJ0</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm enjoying this keyboard, I'm getting anothe...</td>\n",
       "      <td>08 31, 2010</td>\n",
       "      <td>AXNOW20FQKHVW</td>\n",
       "      <td>B. Hayashi</td>\n",
       "      <td>Superb keyboard + solution for slow wake up an...</td>\n",
       "      <td>1.283213e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000EITTLE</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall, this is a fantastic camera that I'm e...</td>\n",
       "      <td>02 3, 2008</td>\n",
       "      <td>A10KCAK279LO0W</td>\n",
       "      <td>mmcwatters \"macdadi80\"</td>\n",
       "      <td>One qualm: not great in low light</td>\n",
       "      <td>1.201997e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006CRXK4S</td>\n",
       "      <td>5</td>\n",
       "      <td>These work very well with mySamsung PN64D7000 ...</td>\n",
       "      <td>01 28, 2012</td>\n",
       "      <td>A19XXLMZXR764J</td>\n",
       "      <td>S. Garfinkle</td>\n",
       "      <td>Work great, fit well</td>\n",
       "      <td>1.327709e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000HDJXNA        1  What I recieved is not what is pictured here O...   \n",
       "1  B006KKS7XQ        5  Excellent unit and a pretty simple install usi...   \n",
       "2  B002NP8XJ0        5  I'm enjoying this keyboard, I'm getting anothe...   \n",
       "3  B000EITTLE        4  Overall, this is a fantastic camera that I'm e...   \n",
       "4  B006CRXK4S        5  These work very well with mySamsung PN64D7000 ...   \n",
       "\n",
       "    reviewTime      reviewerID                   reviewerName  \\\n",
       "0  12 26, 2012  A29YXBFTD7QUP3                            HHA   \n",
       "1  09 20, 2013  A3IMTXFYD7CGDN  Peter W. George \"soyflakeman\"   \n",
       "2  08 31, 2010   AXNOW20FQKHVW                     B. Hayashi   \n",
       "3   02 3, 2008  A10KCAK279LO0W         mmcwatters \"macdadi80\"   \n",
       "4  01 28, 2012  A19XXLMZXR764J                   S. Garfinkle   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0                                      Buyer be ware    1.356480e+09  \n",
       "1                    high quality without high price    1.379635e+09  \n",
       "2  Superb keyboard + solution for slow wake up an...    1.283213e+09  \n",
       "3                  One qualm: not great in low light    1.201997e+09  \n",
       "4                               Work great, fit well    1.327709e+09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon=pd.read_csv(\"E:/Term3/ud/datasets/amazon_reviews_big.csv\")\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=amazon['reviewText'].fillna('').str.lower()\n",
    "docs=docs.str.replace('[^a-z ]','')\n",
    "\n",
    "\n",
    "docs_clean=[]\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['','work','use','one','like'])\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "for doc in docs:\n",
    "    words=doc.split(\" \")\n",
    "    words_clean=[stemmer.stem(word) for word in words if word not in stopwords ]\n",
    "    words_clean=[word for word in words_clean if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reciev',\n",
       " 'pictur',\n",
       " 'advert',\n",
       " 'vidio',\n",
       " 'cabl',\n",
       " 'job',\n",
       " 'need',\n",
       " 'look',\n",
       " 'high',\n",
       " 'qualiti',\n",
       " 'cabl',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'reciev',\n",
       " 'cheap',\n",
       " 'thin',\n",
       " 'flimsi',\n",
       " 'cabl',\n",
       " 'gold',\n",
       " 'plate',\n",
       " 'anyth',\n",
       " 'els',\n",
       " 'claim',\n",
       " 'bait',\n",
       " 'switch',\n",
       " 'mistak',\n",
       " 'order',\n",
       " 'know',\n",
       " 'attempt',\n",
       " 'contact',\n",
       " 'sender',\n",
       " 'find',\n",
       " 'contact',\n",
       " 'seller',\n",
       " 'told',\n",
       " 'contact',\n",
       " 'amazoncom',\n",
       " 'amazoncom',\n",
       " 'good',\n",
       " 'enough',\n",
       " 'give',\n",
       " 'refund',\n",
       " 'good',\n",
       " 'cabl',\n",
       " 'woth',\n",
       " 'need',\n",
       " 'run',\n",
       " 'wife',\n",
       " 'kareoke',\n",
       " 'tv',\n",
       " 'thing',\n",
       " 'els',\n",
       " 'would',\n",
       " 'sent',\n",
       " 'back',\n",
       " 'full',\n",
       " 'refund',\n",
       " 'im',\n",
       " 'surpris',\n",
       " 'item',\n",
       " 'still',\n",
       " 'list',\n",
       " 'high',\n",
       " 'grade',\n",
       " 'cabl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictionary=gensim.corpora.Dictionary(docs_clean) ## assign numerical values to the words in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list(zip(dictinary,keys(),dictionary.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary.doc2bow(docs_clean[0])\n",
    "## arranging with number of frequency of each word(which are now represented by numerical number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow=[]\n",
    "for doc in docs_clean:\n",
    "    bow=dictionary.doc2bow(doc)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=4) ## id2word is for use actually mapped values that are in the dictionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.106950246), (2, 0.88467264)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(docs_bow[0]) ## its shows number of topics with their probability,so here we have two topics with\n",
    "                                           ## with their probability .    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2topic=pd.DataFrame(lda_model.get_document_topics(docs_bow[0]),columns=['topic_no','prob'])\n",
    "doc2topic.sort_values('prob',ascending=False).iloc[0]['topic_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=[]\n",
    "for bow in docs_bow:\n",
    "    doc2topic=pd.DataFrame(lda_model.get_document_topics(bow),columns=['topic_no','prob'])\n",
    "    topic=doc2topic.sort_values('prob',ascending=False)\n",
    "    topic=topic.iloc[0]['topic_no']\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"use\" + 0.015*\"work\" + 0.011*\"drive\" + 0.009*\"one\" + 0.009*\"usb\" + 0.007*\"comput\" + 0.007*\"devic\" + 0.007*\"connect\" + 0.007*\"get\" + 0.006*\"card\"'),\n",
       " (1,\n",
       "  '0.031*\"camera\" + 0.018*\"batteri\" + 0.016*\"use\" + 0.014*\"len\" + 0.008*\"pictur\" + 0.007*\"take\" + 0.007*\"one\" + 0.007*\"great\" + 0.007*\"get\" + 0.007*\"good\"'),\n",
       " (2,\n",
       "  '0.013*\"use\" + 0.013*\"case\" + 0.012*\"one\" + 0.011*\"work\" + 0.010*\"like\" + 0.008*\"cabl\" + 0.008*\"well\" + 0.008*\"great\" + 0.007*\"would\" + 0.007*\"get\"'),\n",
       " (3,\n",
       "  '0.021*\"sound\" + 0.012*\"speaker\" + 0.011*\"use\" + 0.010*\"tv\" + 0.009*\"good\" + 0.009*\"qualiti\" + 0.008*\"great\" + 0.008*\"headphon\" + 0.007*\"player\" + 0.007*\"set\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATSET--> abcnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc=pd.read_csv(\"E:/Term3/ud/datasets/abcnews.csv\")\n",
    "abc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103665, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "abc_new=abc.sample(100000)\n",
    "abc_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_docs=abc_new['headline_text'].fillna('').str.lower()\n",
    "abc_docs=abc_docs.str.replace('[^a-z]','')\n",
    "\n",
    "docs_clean=[]\n",
    "\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "for doc in abc_docs:\n",
    "    words=doc.split(\" \")\n",
    "    words_clean=[stemmer.stem(word) for word in words if word not in stopwords ]\n",
    "    words_clean=[word for word in words_clean if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow=[]\n",
    "for doc in docs_clean:\n",
    "    bow=dictionary.doc2bow(doc)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model=gensim.models.LdaModel(docs_bow,id2word=dictionary,num_topics=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=[]\n",
    "for bow in docs_bow:\n",
    "    doc2topic=pd.DataFrame(lda_model.get_document_topics(bow),columns=['topic_no','prob'])\n",
    "    topic=doc2topic.sort_values('prob',ascending=False)\n",
    "    topic=topic.iloc[0]['topic_no']\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"ntchpodcast\" + 0.003*\"closeram\" + 0.000*\"closer\" + 0.000*\"abcnew\" + 0.000*\"marketwrap\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\"'),\n",
       " (1,\n",
       "  '0.002*\"kohlerreport\" + 0.002*\"countrywid\" + 0.000*\"abcbusinessnew\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"themix\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\"'),\n",
       " (2,\n",
       "  '0.000*\"nationalruralnew\" + 0.000*\"thedrumtuesdayaugust\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\" + 0.000*\"interviewivanhenjak\" + 0.000*\"thedrumtuesdayseptemb\" + 0.000*\"abcbusi\"'),\n",
       " (3,\n",
       "  '0.005*\"abcweath\" + 0.005*\"closerpm\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\" + 0.000*\"interviewivanhenjak\" + 0.000*\"thedrumtuesdayseptemb\"'),\n",
       " (4,\n",
       "  '0.001*\"sachpodcast\" + 0.001*\"interviewrickypont\" + 0.000*\"interviewbradarthur\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\" + 0.000*\"interviewivanhenjak\"'),\n",
       " (5,\n",
       "  '0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\" + 0.000*\"interviewivanhenjak\" + 0.000*\"thedrumtuesdayseptemb\" + 0.000*\"abcbusi\" + 0.000*\"interviewneilhenri\"'),\n",
       " (6,\n",
       "  '0.001*\"abcentertainmentnew\" + 0.000*\"nationalruralnewsforfriday\" + 0.000*\"inthestudiowithrogermontgomeri\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"missingmanfoundsaf\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\"'),\n",
       " (7,\n",
       "  '0.006*\"abcsport\" + 0.000*\"interviewewenmckenzi\" + 0.000*\"nationalruralnew\" + 0.000*\"abcbusinessnewsandmarketanalysi\" + 0.000*\"ruralqldpodcast\" + 0.000*\"australiansharemarketopenshigh\" + 0.000*\"abcentertain\" + 0.000*\"interviewtimsheen\" + 0.000*\"interviewivanhenjak\" + 0.000*\"viccountryhourseptemb\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
